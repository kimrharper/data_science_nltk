{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD, PCA, SparsePCA, NMF\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC, SVR\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "np.seterr(divide='warn', invalid='warn'); sns.set_style(\"whitegrid\");warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Bosch Manufacturing Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ [Ryan Harper](www.kimrharper.com) <br><br>\n",
    "__Data Source:__ [Bosch Dataset via Kaggle](https://www.kaggle.com/c/bosch-production-line-performance/data) <br> <br>\n",
    "__Background:__ Bosch is a home appliance and industrial tools manufacturing company. In 2017, Bosch supplied Kaggle.com with manufacturing data to promote a competition. The goal of the competition was to determine factors that influence whether or not the product passes the final response stage of manufacturing and to predict which products are likely to fail based on this manufacturing process.<br> <br>\n",
    "__The Data:__ Early exploration of this data will use a subset of the big data provided by Bosch. The data is provided by [Hitesh, John, and Matthew via PDX Data Science Meetup](https://www.meetup.com/Portland-Data-Science-Group/events/257370691/). The data subset is divided into 2 groups of 3 files (3 training, 3 test). Each group has one csv file each for numerical features ('numeric'), dates ('date'), and the manufacturing path ('cat'). The data subset includes a larger percentage of products that failed the response test, but not much more is known about this subsampling method.<br><br>\n",
    "__Assumptions:__ ID # represents a specific product and that there is only one product. The differences in assembly are due to customization and/or differences between lines.<br><br>\n",
    "__Goal:__ Predict which products will fail the response test. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import numerical data\n",
    "mf_num_data = pd.read_csv('bosch_small_data/train_numeric.csv',low_memory=False)\n",
    "\n",
    "# import date data\n",
    "mf_date_data = pd.read_csv('bosch_small_data/train_date.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Functions and Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process X values with transformation and imputation if need\n",
    "def process_data(df, transform):\n",
    "    names = list(df.columns)\n",
    "    if transform:\n",
    "        pt = PowerTransformer()\n",
    "        df = pt.fit_transform(df)\n",
    "    impute_constant = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    \n",
    "    return impute_constant.fit_transform(df), names\n",
    "\n",
    "# visualize data by components\n",
    "def visualize_data(pipeline,dimred):\n",
    "    feature_plot = list(zip(features, pipeline.named_steps[dimred].components_[0]))\n",
    "    feature_plot = pd.DataFrame(data=feature_plot)\n",
    "    feature_plot = pd.DataFrame(feature_plot.sort_values(1, ascending=False).iloc[0:10])\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.title('Ordered by variance')\n",
    "    sns.barplot(x=0, y=1, data=feature_plot, palette=sns.color_palette(\"cool\"))\n",
    "    plt.ylim(feature_plot[1].min(),feature_plot[1].max())\n",
    "    plt.savefig(dimred+'-top10.png')\n",
    "    plt.show()\n",
    "     \n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.title('Component Variance')\n",
    "    plt.plot(pipeline.named_steps[dimred].explained_variance_ratio_)\n",
    "\n",
    "# Get the last recorded time\n",
    "def final_time(df,row_ind):\n",
    "    time = df.iloc[row_ind,1:].dropna().iloc[-2]\n",
    "    response = df.iloc[row_ind,-1]\n",
    "    return time,response\n",
    "\n",
    "ms_mcc = make_scorer(matthews_corrcoef)\n",
    "test_per = .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 55.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "last_time =[]\n",
    "for i in range(len(mf_date_data.iloc[:,1:-1])):\n",
    "    try:\n",
    "        lt, sc = final_time(mf_date_data,i)\n",
    "        last_time.append(lt)\n",
    "    except:\n",
    "        last_time.append(0)\n",
    "last_time = np.array(last_time)\n",
    "mn, mx = last_time.min(), last_time.max()\n",
    "last_time = ((last_time - mn) / (mx - mn)) * 2 - 1\n",
    "mf_num_data.insert(1, 'end_time', last_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, features = process_data(mf_num_data.iloc[:,1:-1], False)\n",
    "y = mf_num_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=test_per, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS = [700, len(X[0,:])]\n",
    "RF_DEPTH = [150]\n",
    "RF_ESTIM =  [150]\n",
    "\n",
    "pipe = Pipeline([('reduce_dim', None), ('model', None)])\n",
    "             \n",
    "params = [\n",
    "    {\n",
    "        'reduce_dim': [PCA()],\n",
    "        'reduce_dim__n_components': N_COMPONENTS,\n",
    "        'model': [RandomForestClassifier()],\n",
    "        'model__max_depth': RF_DEPTH,\n",
    "        'model__n_estimators': RF_ESTIM,\n",
    "    },\n",
    "    {\n",
    "        'reduce_dim': [PCA()],\n",
    "        'reduce_dim__n_components': N_COMPONENTS,\n",
    "        'model': [LinearSVC(), SGDClassifier(), BernoulliNB()],\n",
    "    }]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=params, cv=3, n_jobs=4, scoring=ms_mcc, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results = pd.DataFrame(grid.cv_results_)\n",
    "columns = ['param_model',\n",
    "           'param_reduce_dim__n_components',\n",
    "           'param_model__max_depth',\n",
    "           'param_model__n_estimators',\n",
    "           'mean_test_score',\n",
    "           'rank_test_score',\n",
    "           'mean_fit_time']\n",
    "grid_results = grid_results[columns]\n",
    "grid_results['param_model']=grid_results['param_model'].apply(lambda val: str(val).split('(')[0])\n",
    "grid_results = grid_results.sort_values('rank_test_score')\n",
    "grid_results.to_html('pca_models_evaluation_maxed_transform_model_selection.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_reduce_dim__n_components</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>700</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.284100</td>\n",
       "      <td>1</td>\n",
       "      <td>548.349306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>968</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.279433</td>\n",
       "      <td>2</td>\n",
       "      <td>369.165934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.226055</td>\n",
       "      <td>3</td>\n",
       "      <td>255.989763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.226055</td>\n",
       "      <td>3</td>\n",
       "      <td>66.087134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.178393</td>\n",
       "      <td>5</td>\n",
       "      <td>26.150956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.175834</td>\n",
       "      <td>6</td>\n",
       "      <td>37.088741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102116</td>\n",
       "      <td>7</td>\n",
       "      <td>43.646047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.089966</td>\n",
       "      <td>8</td>\n",
       "      <td>22.052156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              param_model param_reduce_dim__n_components  \\\n",
       "0  RandomForestClassifier                            700   \n",
       "1  RandomForestClassifier                            968   \n",
       "2               LinearSVC                            700   \n",
       "3               LinearSVC                            968   \n",
       "5           SGDClassifier                            968   \n",
       "4           SGDClassifier                            700   \n",
       "6             BernoulliNB                            700   \n",
       "7             BernoulliNB                            968   \n",
       "\n",
       "  param_model__max_depth param_model__n_estimators  mean_test_score  \\\n",
       "0                    150                       150         0.284100   \n",
       "1                    150                       150         0.279433   \n",
       "2                    NaN                       NaN         0.226055   \n",
       "3                    NaN                       NaN         0.226055   \n",
       "5                    NaN                       NaN         0.178393   \n",
       "4                    NaN                       NaN         0.175834   \n",
       "6                    NaN                       NaN         0.102116   \n",
       "7                    NaN                       NaN         0.089966   \n",
       "\n",
       "   rank_test_score  mean_fit_time  \n",
       "0                1     548.349306  \n",
       "1                2     369.165934  \n",
       "2                3     255.989763  \n",
       "3                3      66.087134  \n",
       "5                5      26.150956  \n",
       "4                6      37.088741  \n",
       "6                7      43.646047  \n",
       "7                8      22.052156  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, features = process_data(mf_num_data.iloc[:,1:-1], False)\n",
    "y = mf_num_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=test_per, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = RandomForestClassifier()\n",
    "selector = RFE(estimator, step=.05)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "RFE_selection = pd.DataFrame(list(zip(mf_num_data.columns[1:-1],selector.ranking_)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(1,19):\n",
    "    step_features = RFE_selection[0][RFE_selection[1] <= i].values\n",
    "    X, features = process_data(mf_num_data[step_features], False)\n",
    "    y = mf_num_data.iloc[:,-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=test_per, random_state=42)\n",
    "    rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', oob_score=True)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_predict = rf.predict(X_test)\n",
    "    print(matthews_corrcoef(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = RFE_selection[0][RFE_selection[1] <= 1].values\n",
    "X, features = process_data(mf_num_data[top_features], True)\n",
    "y = mf_num_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=test_per, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4078209370113893\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(matthews_corrcoef(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    8.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41037390395473183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, criterion='entropy', n_jobs=4,class_weight='balanced', verbose=1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(matthews_corrcoef(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
