{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mf_dimensionality_reduction import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __<font color='blue'>Bosch Manufacturing</font>__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __<font color='darkblue'> Part 4: Dimensionality Reduction</font>__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ [Ryan Harper](www.kimrharper.com) <br><br>\n",
    "__Data Source:__ [Bosch Dataset via Kaggle](https://www.kaggle.com/c/bosch-production-line-performance/data) <br> <br>\n",
    "__Background:__ Bosch is a home appliance and industrial tools manufacturing company. In 2017, Bosch supplied Kaggle.com with manufacturing data to promote a competition. The goal of the competition was to determine factors that influence whether or not the product passes the final response stage of manufacturing and to predict which products are likely to fail based on this manufacturing process.<br> <br>\n",
    "__The Data:__ Early exploration of this data will use a subset of the big data provided by Bosch. The data is provided by [Hitesh, John, and Matthew via PDX Data Science Meetup](https://www.meetup.com/Portland-Data-Science-Group/events/257370691/). The data subset is divided into 2 groups of 3 files (3 training, 3 test). Each group has one csv file each for numerical features ('numeric'), dates ('date'), and the manufacturing path ('cat'). The data subset includes a larger percentage of products that failed the response test, but not much more is known about this subsampling method.<br><br>\n",
    "__Assumptions:__ ID # represents a specific product and that there is only one product. The differences in assembly are due to customization and/or differences between lines.<br><br>\n",
    "__Goal:__ Predict which products will fail the response test. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Import Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%store -r sig_diff_list\n",
    "sig_diff_list.append(len(mf_num_data.columns)-1) # Adding response column index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = mf_num_data.append(mf_date_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r skewed_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Functions and Declarations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "last_time =[]\n",
    "for i in range(len(mf_date_data.iloc[:,1:-1])):\n",
    "    try:\n",
    "        lt, sc = final_time(mf_date_data,i)\n",
    "        last_time.append(lt)\n",
    "    except:\n",
    "        last_time.append(0)\n",
    "last_time = np.array(last_time)\n",
    "mn, mx = last_time.min(), last_time.max()\n",
    "last_time = ((last_time - mn) / (mx - mn)) * 2 - 1\n",
    "mf_num_data.insert(1, 'end_time', last_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_F0</th>\n",
       "      <th>L0_S0_F2</th>\n",
       "      <th>L0_S0_F4</th>\n",
       "      <th>L0_S0_F6</th>\n",
       "      <th>L0_S0_F8</th>\n",
       "      <th>L0_S0_F10</th>\n",
       "      <th>L0_S0_F12</th>\n",
       "      <th>L0_S0_F14</th>\n",
       "      <th>L0_S0_F16</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_F4245</th>\n",
       "      <th>L3_S50_F4247</th>\n",
       "      <th>L3_S50_F4249</th>\n",
       "      <th>L3_S50_F4251</th>\n",
       "      <th>L3_S50_F4253</th>\n",
       "      <th>L3_S51_F4256</th>\n",
       "      <th>L3_S51_F4258</th>\n",
       "      <th>L3_S51_F4260</th>\n",
       "      <th>L3_S51_F4262</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>-0.167</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.248</td>\n",
       "      <td>0.163</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.025</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 970 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  L0_S0_F0  L0_S0_F2  L0_S0_F4  L0_S0_F6  L0_S0_F8  L0_S0_F10  L0_S0_F12  \\\n",
       "0  23       NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "1  71    -0.167    -0.168     0.276     0.330     0.074      0.161      0.052   \n",
       "2  76       NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "3  86    -0.003     0.041    -0.033    -0.016     0.074      0.161      0.000   \n",
       "4  97       NaN       NaN       NaN       NaN       NaN        NaN        NaN   \n",
       "\n",
       "   L0_S0_F14  L0_S0_F16    ...     L3_S50_F4245  L3_S50_F4247  L3_S50_F4249  \\\n",
       "0        NaN        NaN    ...              NaN           NaN           NaN   \n",
       "1      0.248      0.163    ...              NaN           NaN           NaN   \n",
       "2        NaN        NaN    ...              NaN           NaN           NaN   \n",
       "3     -0.072      0.025    ...              NaN           NaN           NaN   \n",
       "4        NaN        NaN    ...              NaN           NaN           NaN   \n",
       "\n",
       "   L3_S50_F4251  L3_S50_F4253  L3_S51_F4256  L3_S51_F4258  L3_S51_F4260  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S51_F4262  Response  \n",
       "0           NaN       0.0  \n",
       "1           NaN       0.0  \n",
       "2           NaN       0.0  \n",
       "3           NaN       0.0  \n",
       "4           NaN       0.0  \n",
       "\n",
       "[5 rows x 970 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf_num_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __PCA__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = process_data(merged_df, True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "N_COMPONENTS = [100, 200]\n",
    "RF_DEPTH = [150]\n",
    "RF_ESTIM =  [150]\n",
    "\n",
    "pipe = Pipeline([('reduce_dim', None), ('model', None)])\n",
    "             \n",
    "params = [\n",
    "    {   # PCA with Random Forest\n",
    "        'reduce_dim': [PCA()],\n",
    "        'reduce_dim__n_components': N_COMPONENTS,\n",
    "        'model': [RandomForestClassifier()],\n",
    "        'model__max_depth': RF_DEPTH,\n",
    "        'model__n_estimators': RF_ESTIM,\n",
    "    },\n",
    "    {   # PCA with LinearSVC, SGDClassifier, and GaussianNB\n",
    "        'reduce_dim': [PCA()],\n",
    "        'reduce_dim__n_components': N_COMPONENTS,\n",
    "        'model': [LinearSVC(), SGDClassifier(),GaussianNB()],\n",
    "    },\n",
    "    {   # LinearSVC, SGDClassifier, GaussianNB, and RandomForest w/out PCA\n",
    "        'model': [LinearSVC(), SGDClassifier(), GaussianNB(), RandomForestClassifier(max_depth=150, n_estimators=150)],\n",
    "    }]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=params, cv=3, n_jobs=4, scoring=ms_mcc, verbose=10)\n",
    "grid.fit(X_train, y_train)\n",
    "print('--FINISHED--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_reduce_dim__n_components</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255190</td>\n",
       "      <td>1</td>\n",
       "      <td>54.974408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.241637</td>\n",
       "      <td>2</td>\n",
       "      <td>187.838954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>0.223650</td>\n",
       "      <td>3</td>\n",
       "      <td>148.713018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.209320</td>\n",
       "      <td>4</td>\n",
       "      <td>21.459370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.183070</td>\n",
       "      <td>5</td>\n",
       "      <td>32.930122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.159808</td>\n",
       "      <td>6</td>\n",
       "      <td>0.655708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136866</td>\n",
       "      <td>7</td>\n",
       "      <td>13.815488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.131329</td>\n",
       "      <td>8</td>\n",
       "      <td>24.683609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.056380</td>\n",
       "      <td>9</td>\n",
       "      <td>7.358641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052989</td>\n",
       "      <td>10</td>\n",
       "      <td>6.562519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020466</td>\n",
       "      <td>11</td>\n",
       "      <td>1.003536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12</td>\n",
       "      <td>10.541602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               param_model param_reduce_dim__n_components  \\\n",
       "11  RandomForestClassifier                            NaN   \n",
       "1   RandomForestClassifier                            200   \n",
       "0   RandomForestClassifier                            100   \n",
       "8                LinearSVC                            NaN   \n",
       "3                LinearSVC                            200   \n",
       "9            SGDClassifier                            NaN   \n",
       "5            SGDClassifier                            200   \n",
       "2                LinearSVC                            100   \n",
       "6               GaussianNB                            100   \n",
       "7               GaussianNB                            200   \n",
       "10              GaussianNB                            NaN   \n",
       "4            SGDClassifier                            100   \n",
       "\n",
       "   param_model__max_depth param_model__n_estimators  mean_test_score  \\\n",
       "11                    NaN                       NaN         0.255190   \n",
       "1                     150                       150         0.241637   \n",
       "0                     150                       150         0.223650   \n",
       "8                     NaN                       NaN         0.209320   \n",
       "3                     NaN                       NaN         0.183070   \n",
       "9                     NaN                       NaN         0.159808   \n",
       "5                     NaN                       NaN         0.136866   \n",
       "2                     NaN                       NaN         0.131329   \n",
       "6                     NaN                       NaN         0.056380   \n",
       "7                     NaN                       NaN         0.052989   \n",
       "10                    NaN                       NaN         0.020466   \n",
       "4                     NaN                       NaN         0.000000   \n",
       "\n",
       "    rank_test_score  mean_fit_time  \n",
       "11                1      54.974408  \n",
       "1                 2     187.838954  \n",
       "0                 3     148.713018  \n",
       "8                 4      21.459370  \n",
       "3                 5      32.930122  \n",
       "9                 6       0.655708  \n",
       "5                 7      13.815488  \n",
       "2                 8      24.683609  \n",
       "6                 9       7.358641  \n",
       "7                10       6.562519  \n",
       "10               11       1.003536  \n",
       "4                12      10.541602  "
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = ['param_model','param_reduce_dim__n_components','param_model__max_depth','param_model__n_estimators','mean_test_score','rank_test_score','mean_fit_time']\n",
    "display_results(grid, columns, 'visuals/pca_models_fixed_imbalance.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __RFE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Recreate Train/Test Data:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = process_data(mf_num_data.iloc[:,sig_diff_list], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "estimator = RandomForestClassifier()\n",
    "selector = RFE(estimator, step=.05)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "RFE_selection = pd.DataFrame(list(zip(mf_num_data.columns[1:-1],selector.ranking_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = RFE_selection[0][RFE_selection[1] <= 1].values\n",
    "X, features = process_data(mf_num_data[top_features], True)\n",
    "y = mf_num_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=test_per, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__RF Run 1:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4078209370113893\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(matthews_corrcoef(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__RF Run 2:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    8.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41037390395473183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, criterion='entropy', n_jobs=4,class_weight='balanced', verbose=1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(matthews_corrcoef(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__RF Run 3:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    3.6s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    8.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41037390395473183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, criterion='entropy', n_jobs=4,class_weight='balanced', verbose=1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(matthews_corrcoef(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = mf_num_data.append(mf_date_data)\n",
    "# merged_df.isna().any()[lambda x: x]\n",
    "merged_df = merged_df.fillna(merged_df.mean())\n",
    "drop_nans = list(merged_df.isna().any()[lambda x: x].index)\n",
    "merged_df.drop(drop_nans, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = process_data(merged_df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier(criterion='entropy', n_jobs=4,class_weight='balanced')\n",
    "selector = RFE(estimator, n_features_to_select=100, step=20)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "RFE_selection = pd.DataFrame(list(zip(mf_num_data.columns[1:-1],selector.ranking_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10043317273403868\n",
      "0.0056352459675123225\n",
      "0.04274652775491485\n",
      "0.046288084158344525\n",
      "0.05516374148211885\n",
      "0.059436897085631143\n",
      "0.028117240709158435\n",
      "0.0838616050763581\n",
      "0.027989863995858334\n",
      "0.055090995256066796\n",
      "0.06186097549568627\n",
      "0.03586270849175873\n",
      "0.047463389098834075\n",
      "0.03356427920727333\n",
      "0.0305565362706007\n",
      "0.025231454159691104\n",
      "0.045266019416444085\n",
      "0.05235087446168564\n",
      "0.05517925734363526\n"
     ]
    }
   ],
   "source": [
    "get_probs = []\n",
    "for i in range(1,20):\n",
    "    top_features = RFE_selection[0][RFE_selection[1] == i].values\n",
    "    top_features2 = list(top_features)\n",
    "    top_features2.append('Response')\n",
    "    X_train, X_test, y_train, y_test = process_data(merged_df[top_features2], True)\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_predict = rf.predict(X_test)\n",
    "    print(matthews_corrcoef(y_test, y_predict))\n",
    "    get_probs.append(rf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF = pd.DataFrame()\n",
    "for r in range(len(get_probs)):\n",
    "    r_prob = get_probs[r]\n",
    "    newDF[r] = r_prob[:,0]\n",
    "    success_prob = newDF.mean(axis=1)\n",
    "    \n",
    "    r_prob = get_probs[r]\n",
    "    newDF[r] = r_prob[:,1]\n",
    "    fail_prob = newDF.mean(axis=1)\n",
    "\n",
    "make_predictions = pd.DataFrame([success_prob, fail_prob]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(a,b):\n",
    "    return 0 if a > b else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [compare(make_predictions.iloc[i,:][0],make_predictions.iloc[i,:][1]) for i in range(len(make_predictions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05212786485008331\n"
     ]
    }
   ],
   "source": [
    "print(matthews_corrcoef(y_test, results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Best Prediction:__ <br>\n",
    "0.41037390395473183<br>RandomForestClassifier(n_estimators=100, criterion='entropy', n_jobs=4,class_weight='balanced', verbose=1) <br>RFE(estimator, step=.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
