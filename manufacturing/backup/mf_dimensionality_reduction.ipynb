{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_numeric.csv loaded...\n",
      "train_date.csv loaded...\n",
      "test_numeric.csv loaded...\n",
      "test_date.csv loaded...\n"
     ]
    }
   ],
   "source": [
    "from utils.mf_dimensionality_reduction import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __<font color='blue'>Bosch Manufacturing</font>__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __<font color='darkblue'> Part 4: Dimensionality Reduction</font>__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ [Ryan Harper](www.kimrharper.com) <br><br>\n",
    "__Data Source:__ [Bosch Dataset via Kaggle](https://www.kaggle.com/c/bosch-production-line-performance/data) <br> <br>\n",
    "__Background:__ Bosch is a home appliance and industrial tools manufacturing company. In 2017, Bosch supplied Kaggle.com with manufacturing data to promote a competition. The goal of the competition was to determine factors that influence whether or not the product passes the final response stage of manufacturing and to predict which products are likely to fail based on this manufacturing process.<br> <br>\n",
    "__The Data:__ Early exploration of this data will use a subset of the big data provided by Bosch. The data is provided by [Hitesh, John, and Matthew via PDX Data Science Meetup](https://www.meetup.com/Portland-Data-Science-Group/events/257370691/). The data subset is divided into 2 groups of 3 files (3 training, 3 test). Each group has one csv file each for numerical features ('numeric'), dates ('date'), and the manufacturing path ('cat'). The data subset includes a larger percentage of products that failed the response test, but not much more is known about this subsampling method.<br><br>\n",
    "__Assumptions:__ ID # represents a specific product and that there is only one product. The differences in assembly are due to customization and/or differences between lines.<br><br>\n",
    "__Goal:__ Predict which products will fail the response test. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve vars from mf_stats_analysis.ipynb | quick var import\n",
    "%store -r skewed_features\n",
    "%store -r sig_diff_list\n",
    "sig_diff_list.append(len(mf_num_data.columns)-1) # Adding response column index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_mcc = make_scorer(matthews_corrcoef)\n",
    "TEST_PER = .3\n",
    "\n",
    "def process_predictions(df):\n",
    "    Xtr = df.iloc[:,:-1]\n",
    "    Xtr = Xtr.fillna(Xtrdf.mean())\n",
    "    Xtr = Xtr.dropna(axis=1, how='all')\n",
    "    ytr = df.iloc[:,-1]\n",
    "    Xte = mf_merged_test.fillna(mf_num_data_test.mean())\n",
    "    Xte = Xte.dropna(axis=1, how='all')\n",
    "    print(Xtr.values.shape)\n",
    "    print(Xte.values.shape)\n",
    "    print(ytr.values.shape)\n",
    "        \n",
    "    return Xtr.values, ytr.values, Xte.values\n",
    "\n",
    "def save_to_csv(pred, title):\n",
    "    final_predic = pd.DataFrame(mf_merged_test.iloc[:,0])\n",
    "    print(len(final_pred))\n",
    "    print(len(pred))\n",
    "    final_predic['Response'] = pred\n",
    "    pd.DataFrame(final_predic).to_csv(title) \n",
    "    \n",
    "def final_predictions(data, title):\n",
    "    X_train, y_train, X_test = process_predictions(data)\n",
    "    rf = RandomForestClassifier(n_estimators=100, criterion='entropy', n_jobs=4, class_weight='balanced', verbose=1)\n",
    "    print(y_train)\n",
    "    rf.fit(X_train, y_train)\n",
    "    predictions = rf.predict(X_test)\n",
    "    save_to_csv(predictions, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = merged_df\n",
    "for f in skewed_features:\n",
    "    transformed_df[f] = np.log(1+ transformed_df[f])\n",
    "all_transformed_df = merged_df\n",
    "for f in list(all_transformed_df.columns[1:-1]):\n",
    "    all_transformed_df[f] = np.log(1+ all_transformed_df[f])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139484, 2115)\n",
      "(15498, 2114)\n",
      "(139484,)\n",
      "[1009.2530431 1009.2530431 1009.2530431 ... 1009.2530431 1009.2530431\n",
      " 1009.2530431]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0269b7becfbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf_merged_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RH-ND-NoTransform.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-938ad4181e6f>\u001b[0m in \u001b[0;36mfinal_predictions\u001b[0;34m(data, title)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mrf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'entropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0msave_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/data_science_projects-yURdgCV2/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mDOUBLE\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/data_science_projects-yURdgCV2/lib/python3.6/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_y_class_weight\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_y_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/data_science_projects-yURdgCV2/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    169\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    170\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "final_predictions(mf_merged_train, 'RH-ND-NoTransform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions(transformed_df, 'RH-ND-SkewTransform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions(all_transformed_df, 'RH-ND-AllTransform.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "merged_df = mf_num_data.append(mf_date_data)\n",
    "X_train, X_test, y_train, y_test = process_data(merged_df, True)\n",
    "final_series = pd.DataFrame(pd.DataFrame(X_train).isnull().sum())\n",
    "final_series[final_series[0]>0]\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='entropy', n_jobs=4,class_weight='balanced', verbose=1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df = merged_df\n",
    "for f in skewed_features:\n",
    "    transformed_df[f] = np.log(1+ transformed_df[f])\n",
    "X_train, X_test, y_train, y_test = process_data(transformed_df, True)\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='entropy', n_jobs=4,class_weight='balanced', verbose=1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(matthews_corrcoef(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_transformed_df = merged_df\n",
    "for f in list(all_transformed_df.columns[1:-1]):\n",
    "    all_transformed_df[f] = np.log(1+ all_transformed_df[f])\n",
    "X_train, X_test, y_train, y_test = process_data(all_transformed_df, True)\n",
    "rf = RandomForestClassifier(n_estimators=100, criterion='entropy', n_jobs=4,class_weight='balanced', verbose=1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(matthews_corrcoef(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Functions and Declarations"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "last_time =[]\n",
    "for i in range(len(mf_date_data.iloc[:,1:-1])):\n",
    "    try:\n",
    "        lt, sc = final_time(mf_date_data,i)\n",
    "        last_time.append(lt)\n",
    "    except:\n",
    "        last_time.append(0)\n",
    "last_time = np.array(last_time)\n",
    "mn, mx = last_time.min(), last_time.max()\n",
    "last_time = ((last_time - mn) / (mx - mn)) * 2 - 1\n",
    "mf_num_data.insert(1, 'end_time', last_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_num_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __PCA__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train, y_test = process_data(merged_df, True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "N_COMPONENTS = [100, 200]\n",
    "RF_DEPTH = [150]\n",
    "RF_ESTIM =  [150]\n",
    "\n",
    "pipe = Pipeline([('reduce_dim', None), ('model', None)])\n",
    "             \n",
    "params = [\n",
    "    {   # PCA with Random Forest\n",
    "        'reduce_dim': [PCA()],\n",
    "        'reduce_dim__n_components': N_COMPONENTS,\n",
    "        'model': [RandomForestClassifier()],\n",
    "        'model__max_depth': RF_DEPTH,\n",
    "        'model__n_estimators': RF_ESTIM,\n",
    "    },\n",
    "    {   # PCA with LinearSVC, SGDClassifier, and GaussianNB\n",
    "        'reduce_dim': [PCA()],\n",
    "        'reduce_dim__n_components': N_COMPONENTS,\n",
    "        'model': [LinearSVC(), SGDClassifier(),GaussianNB()],\n",
    "    },\n",
    "    {   # LinearSVC, SGDClassifier, GaussianNB, and RandomForest w/out PCA\n",
    "        'model': [LinearSVC(), SGDClassifier(), GaussianNB(), RandomForestClassifier(max_depth=150, n_estimators=150)],\n",
    "    }]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=params, cv=3, n_jobs=4, scoring=ms_mcc, verbose=10)\n",
    "grid.fit(X_train, y_train)\n",
    "print('--FINISHED--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['param_model','param_reduce_dim__n_components','param_model__max_depth','param_model__n_estimators','mean_test_score','rank_test_score','mean_fit_time']\n",
    "display_results(grid, columns, 'visuals/pca_models_fixed_imbalance.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __RFE__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Recreate Train/Test Data:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = process_data(mf_num_data.iloc[:,sig_diff_list], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "estimator = RandomForestClassifier()\n",
    "selector = RFE(estimator, step=.05)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "RFE_selection = pd.DataFrame(list(zip(mf_num_data.columns[1:-1],selector.ranking_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = RFE_selection[0][RFE_selection[1] <= 1].values\n",
    "X, features = process_data(mf_num_data[top_features], True)\n",
    "y = mf_num_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=test_per, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__RF Run 1:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(matthews_corrcoef(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__RF Run 2:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, criterion='entropy', n_jobs=4,class_weight='balanced', verbose=1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(matthews_corrcoef(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__RF Run 3:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, criterion='entropy', n_jobs=4,class_weight='balanced', verbose=1)\n",
    "rf.fit(X_train, y_train)\n",
    "y_predict = rf.predict(X_test)\n",
    "print(matthews_corrcoef(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = mf_num_data.append(mf_date_data)\n",
    "# merged_df.isna().any()[lambda x: x]\n",
    "merged_df = merged_df.fillna(merged_df.mean())\n",
    "drop_nans = list(merged_df.isna().any()[lambda x: x].index)\n",
    "merged_df.drop(drop_nans, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = process_data(merged_df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestClassifier(criterion='entropy', n_jobs=4,class_weight='balanced')\n",
    "selector = RFE(estimator, n_features_to_select=100, step=20)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "RFE_selection = pd.DataFrame(list(zip(mf_num_data.columns[1:-1],selector.ranking_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_probs = []\n",
    "for i in range(1,20):\n",
    "    top_features = RFE_selection[0][RFE_selection[1] == i].values\n",
    "    top_features2 = list(top_features)\n",
    "    top_features2.append('Response')\n",
    "    X_train, X_test, y_train, y_test = process_data(merged_df[top_features2], True)\n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_predict = rf.predict(X_test)\n",
    "    print(matthews_corrcoef(y_test, y_predict))\n",
    "    get_probs.append(rf.predict_proba(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF = pd.DataFrame()\n",
    "for r in range(len(get_probs)):\n",
    "    r_prob = get_probs[r]\n",
    "    newDF[r] = r_prob[:,0]\n",
    "    success_prob = newDF.mean(axis=1)\n",
    "    \n",
    "    r_prob = get_probs[r]\n",
    "    newDF[r] = r_prob[:,1]\n",
    "    fail_prob = newDF.mean(axis=1)\n",
    "\n",
    "make_predictions = pd.DataFrame([success_prob, fail_prob]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(a,b):\n",
    "    return 0 if a > b else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [compare(make_predictions.iloc[i,:][0],make_predictions.iloc[i,:][1]) for i in range(len(make_predictions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matthews_corrcoef(y_test, results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Best Prediction:__ <br>\n",
    "0.41037390395473183<br>RandomForestClassifier(n_estimators=100, criterion='entropy', n_jobs=4,class_weight='balanced', verbose=1) <br>RFE(estimator, step=.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
