{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "np.seterr(divide='warn', invalid='warn'); sns.set_style(\"whitegrid\");warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Bosch Manufacturing Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Author:__ [Ryan Harper](www.kimrharper.com) <br><br>\n",
    "__Data Source:__ [Bosch Dataset via Kaggle](https://www.kaggle.com/c/bosch-production-line-performance/data) <br> <br>\n",
    "__Background:__ Bosch is a home appliance and industrial tools manufacturing company. In 2017, Bosch supplied Kaggle.com with manufacturing data to promote a competition. The goal of the competition was to determine factors that influence whether or not the product passes the final response stage of manufacturing and to predict which products are likely to fail based on this manufacturing process.<br> <br>\n",
    "__The Data:__ Early exploration of this data will use a subset of the big data provided by Bosch. The data is provided by [Hitesh, John, and Matthew via PDX Data Science Meetup](https://www.meetup.com/Portland-Data-Science-Group/events/257370691/). The data subset is divided into 2 groups of 3 files (3 training, 3 test). Each group has one csv file each for numerical features ('numeric'), dates ('date'), and the manufacturing path ('cat'). The data subset includes a larger percentage of products that failed the response test, but not much more is known about this subsampling method.<br><br>\n",
    "__Assumptions:__ ID # represents a specific product and that there is only one product. The differences in assembly are due to customization and/or differences between lines.<br><br>\n",
    "__Goal:__ Predict which products will fail the response test. <br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.13 s, sys: 1.19 s, total: 10.3 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# import numerical data\n",
    "mf_num_data = pd.read_csv('bosch_small_data/train_numeric.csv',low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Declare Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(df):\n",
    "    names = list(df.columns)\n",
    "    impute_constant = SimpleImputer(missing_values=np.nan, strategy='constant',fill_value=0)\n",
    "    return impute_constant.fit_transform(df), names\n",
    "\n",
    "def visualize_data(pipeline,dimred):\n",
    "    feature_plot = list(zip(features, pipeline.named_steps[dimred].components_[0]))\n",
    "    feature_plot = pd.DataFrame(data=feature_plot)\n",
    "    feature_plot = pd.DataFrame(feature_plot.sort_values(1, ascending=False).iloc[0:10])\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.title('Ordered by variance')\n",
    "    sns.barplot(x=0, y=1, data=feature_plot, palette=sns.color_palette(\"cool\"))\n",
    "    plt.ylim(feature_plot[1].min(),feature_plot[1].max())\n",
    "    plt.savefig(dimred+'-top10.png')\n",
    "    plt.show()\n",
    "     \n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.title('Component Variance')\n",
    "    plt.plot(pipeline.named_steps[dimred].explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature_plot = list(zip(features, pipeline_pca.named_steps.pca.components_[0]))\n",
    "feature_plot = pd.DataFrame(data=feature_plot)\n",
    "feature_plot = pd.DataFrame(feature_plot.sort_values(1, ascending=False).iloc[0:20])\n",
    "feature_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Split data to x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD, PCA, SparsePCA, NMF\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, features = process_data(mf_num_data.iloc[:,1:-1])\n",
    "y = mf_num_data.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.3, random_state=42)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "logr = LogisticRegression(random_state=42, solver='liblinear', multi_class='ovr')\n",
    "rf = RandomForestClassifier(random_state=42, n_estimators=200, max_depth=10)\n",
    "\n",
    "lrpipeline_tsvd = Pipeline([('tsvd', TruncatedSVD(n_components=200)),\n",
    "                            ('lr', logr)])\n",
    "\n",
    "lrpipeline_pca = Pipeline([('pca', PCA(n_components=200)),\n",
    "                           ('lr', logr)])\n",
    "\n",
    "rfpipeline_pca = Pipeline([('pca', PCA(n_components=200)),\n",
    "                           ('rf', rf)])\n",
    "\n",
    "lrpipeline_tsvd.fit(X_train,y_train)\n",
    "lrpipeline_pca.fit(X_train,y_train)\n",
    "rfpipeline_pca.fit(X_train,y_train)\n",
    "\n",
    "print('LR_TSVD: {}'.format(matthews_corrcoef(y_test,  lrpipeline_tsvd.predict(X_test))))\n",
    "print('LR_PCA: {}'.format(matthews_corrcoef(y_test, lrpipeline_pca.predict(X_test))))\n",
    "print('RF_PCA: {}'.format(matthews_corrcoef(y_test, rfpipeline_pca.predict(X_test))))\n",
    "visualize_data(pipeline_tsvd,'tsvd')\n",
    "visualize_data(pipeline_pca,'pca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    # the reduce_dim stage is populated by the param_grid\n",
    "    ('reduce_dim', None),\n",
    "    ('rf', rf)\n",
    "])\n",
    "\n",
    "# Candidates = 40 (5 Components * 2 RF Depth * 4 Feature Selection Methods)\n",
    "\n",
    "N_FEATURES_OPTIONS = [50,100,500,700]\n",
    "RF_DEPTH = [5, 10, 15]\n",
    "RF_ITER = [10, 20, 30]\n",
    "\n",
    "REDUCER_LABELS = ['PCA', 'TSVD', 'NMF','KBest']\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'reduce_dim': [PCA()],\n",
    "        'reduce_dim__n_components': N_FEATURES_OPTIONS,\n",
    "        'rf__max_depth': RF_DEPTH,\n",
    "        'rf__n_estimators': RF_ITER\n",
    "    },\n",
    "\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, n_jobs=4, scoring=make_scorer(matthews_corrcoef), verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   40.5s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=4)]: Done 108 out of 108 | elapsed: 19.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 3s, sys: 4.22 s, total: 1min 7s\n",
      "Wall time: 19min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('reduce_dim', None), ('rf', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=4,\n",
       "       param_grid=[{'reduce_dim': [PCA(copy=True, iterated_power='auto', n_components=700, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)], 'reduce_dim__n_components': [50, 100, 500, 700], 'rf__max_depth': [5, 10, 15], 'rf__n_estimators': [10, 20, 30]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(matthews_corrcoef), verbose=5)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# digits = load_digits()\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores = np.array(grid.cv_results_['mean_test_score']).reshape(4,3,3)\n",
    "grid_results = pd.DataFrame(grid.cv_results_)\n",
    "columns = ['param_reduce_dim__n_components','param_rf__max_depth','param_rf__n_estimators','mean_test_score','rank_test_score','mean_fit_time']\n",
    "grid_results = grid_results[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_reduce_dim__n_components</th>\n",
       "      <th>param_rf__max_depth</th>\n",
       "      <th>param_rf__n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_fit_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>700</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.180832</td>\n",
       "      <td>1</td>\n",
       "      <td>76.435648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>500</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>0.180494</td>\n",
       "      <td>2</td>\n",
       "      <td>61.436293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>500</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.178530</td>\n",
       "      <td>3</td>\n",
       "      <td>45.387945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>700</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>0.177658</td>\n",
       "      <td>4</td>\n",
       "      <td>65.885553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>500</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.173983</td>\n",
       "      <td>5</td>\n",
       "      <td>49.364575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>700</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.170077</td>\n",
       "      <td>6</td>\n",
       "      <td>71.040724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.164118</td>\n",
       "      <td>7</td>\n",
       "      <td>59.490359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.162946</td>\n",
       "      <td>8</td>\n",
       "      <td>41.090583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.161443</td>\n",
       "      <td>9</td>\n",
       "      <td>62.034734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.159654</td>\n",
       "      <td>10</td>\n",
       "      <td>88.757953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>700</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.158051</td>\n",
       "      <td>11</td>\n",
       "      <td>65.102991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>500</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.157108</td>\n",
       "      <td>12</td>\n",
       "      <td>50.705230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.131936</td>\n",
       "      <td>13</td>\n",
       "      <td>46.611584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>700</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.130021</td>\n",
       "      <td>14</td>\n",
       "      <td>58.735887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>700</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.126330</td>\n",
       "      <td>15</td>\n",
       "      <td>62.899153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>700</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.125768</td>\n",
       "      <td>16</td>\n",
       "      <td>83.341011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.123001</td>\n",
       "      <td>17</td>\n",
       "      <td>47.566413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.118697</td>\n",
       "      <td>18</td>\n",
       "      <td>45.723440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.053716</td>\n",
       "      <td>19</td>\n",
       "      <td>14.479734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>0.052798</td>\n",
       "      <td>20</td>\n",
       "      <td>24.229784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.052048</td>\n",
       "      <td>21</td>\n",
       "      <td>16.168631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>0.050215</td>\n",
       "      <td>22</td>\n",
       "      <td>19.576873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>0.049375</td>\n",
       "      <td>23</td>\n",
       "      <td>21.990795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>0.038962</td>\n",
       "      <td>24</td>\n",
       "      <td>17.267178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.018465</td>\n",
       "      <td>25</td>\n",
       "      <td>10.927564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>26</td>\n",
       "      <td>12.174274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.011883</td>\n",
       "      <td>27</td>\n",
       "      <td>14.845142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>0.011879</td>\n",
       "      <td>28</td>\n",
       "      <td>14.474728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>29</td>\n",
       "      <td>19.153271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0.008402</td>\n",
       "      <td>29</td>\n",
       "      <td>16.467044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>13.387508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>11.953181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>12.818009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>12.507397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>11.367340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31</td>\n",
       "      <td>9.759172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_reduce_dim__n_components param_rf__max_depth param_rf__n_estimators  \\\n",
       "34                            700                  15                     20   \n",
       "26                            500                  15                     30   \n",
       "24                            500                  15                     10   \n",
       "35                            700                  15                     30   \n",
       "25                            500                  15                     20   \n",
       "33                            700                  15                     10   \n",
       "30                            700                  10                     10   \n",
       "21                            500                  10                     10   \n",
       "23                            500                  10                     30   \n",
       "32                            700                  10                     30   \n",
       "31                            700                  10                     20   \n",
       "22                            500                  10                     20   \n",
       "18                            500                   5                     10   \n",
       "27                            700                   5                     10   \n",
       "28                            700                   5                     20   \n",
       "29                            700                   5                     30   \n",
       "19                            500                   5                     20   \n",
       "20                            500                   5                     30   \n",
       "6                              50                  15                     10   \n",
       "17                            100                  15                     30   \n",
       "7                              50                  15                     20   \n",
       "16                            100                  15                     20   \n",
       "8                              50                  15                     30   \n",
       "15                            100                  15                     10   \n",
       "3                              50                  10                     10   \n",
       "12                            100                  10                     10   \n",
       "4                              50                  10                     20   \n",
       "13                            100                  10                     20   \n",
       "14                            100                  10                     30   \n",
       "5                              50                  10                     30   \n",
       "11                            100                   5                     30   \n",
       "10                            100                   5                     20   \n",
       "9                             100                   5                     10   \n",
       "2                              50                   5                     30   \n",
       "1                              50                   5                     20   \n",
       "0                              50                   5                     10   \n",
       "\n",
       "    mean_test_score  rank_test_score  mean_fit_time  \n",
       "34         0.180832                1      76.435648  \n",
       "26         0.180494                2      61.436293  \n",
       "24         0.178530                3      45.387945  \n",
       "35         0.177658                4      65.885553  \n",
       "25         0.173983                5      49.364575  \n",
       "33         0.170077                6      71.040724  \n",
       "30         0.164118                7      59.490359  \n",
       "21         0.162946                8      41.090583  \n",
       "23         0.161443                9      62.034734  \n",
       "32         0.159654               10      88.757953  \n",
       "31         0.158051               11      65.102991  \n",
       "22         0.157108               12      50.705230  \n",
       "18         0.131936               13      46.611584  \n",
       "27         0.130021               14      58.735887  \n",
       "28         0.126330               15      62.899153  \n",
       "29         0.125768               16      83.341011  \n",
       "19         0.123001               17      47.566413  \n",
       "20         0.118697               18      45.723440  \n",
       "6          0.053716               19      14.479734  \n",
       "17         0.052798               20      24.229784  \n",
       "7          0.052048               21      16.168631  \n",
       "16         0.050215               22      19.576873  \n",
       "8          0.049375               23      21.990795  \n",
       "15         0.038962               24      17.267178  \n",
       "3          0.018465               25      10.927564  \n",
       "12         0.012955               26      12.174274  \n",
       "4          0.011883               27      14.845142  \n",
       "13         0.011879               28      14.474728  \n",
       "14         0.008402               29      19.153271  \n",
       "5          0.008402               29      16.467044  \n",
       "11         0.000000               31      13.387508  \n",
       "10         0.000000               31      11.953181  \n",
       "9          0.000000               31      12.818009  \n",
       "2          0.000000               31      12.507397  \n",
       "1          0.000000               31      11.367340  \n",
       "0          0.000000               31       9.759172  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results.sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     n_components=700,\n",
       "1     n_components=700,\n",
       "2     n_components=700,\n",
       "3     n_components=700,\n",
       "4     n_components=700,\n",
       "5     n_components=700,\n",
       "6     n_components=700,\n",
       "7     n_components=700,\n",
       "8     n_components=700,\n",
       "9     n_components=700,\n",
       "10    n_components=700,\n",
       "11    n_components=700,\n",
       "12    n_components=700,\n",
       "13    n_components=700,\n",
       "14    n_components=700,\n",
       "15    n_components=700,\n",
       "16    n_components=700,\n",
       "17    n_components=700,\n",
       "18    n_components=700,\n",
       "19    n_components=700,\n",
       "20    n_components=700,\n",
       "21    n_components=700,\n",
       "22    n_components=700,\n",
       "23    n_components=700,\n",
       "24    n_components=700,\n",
       "25    n_components=700,\n",
       "26    n_components=700,\n",
       "27    n_components=700,\n",
       "28    n_components=700,\n",
       "29    n_components=700,\n",
       "30    n_components=700,\n",
       "31    n_components=700,\n",
       "32    n_components=700,\n",
       "33    n_components=700,\n",
       "34    n_components=700,\n",
       "35    n_components=700,\n",
       "Name: param_reduce_dim, dtype: object"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results['param_reduce_dim'].apply(lambda val: str(val).split()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_components=700,'"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(grid_results['param_reduce_dim'][0]).split()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# scores are in the order of param_grid iteration, which is alphabetical\n",
    "mean_scores = mean_scores.reshape(len(C_OPTIONS), -1, len(N_FEATURES_OPTIONS))\n",
    "# select score for best C\n",
    "mean_scores = mean_scores.max(axis=0)\n",
    "bar_offsets = (np.arange(len(N_FEATURES_OPTIONS)) *\n",
    "               (len(reducer_labels) + 1) + .5)\n",
    "\n",
    "plt.figure()\n",
    "COLORS = 'bgrcmyk'\n",
    "for i, (label, reducer_scores) in enumerate(zip(reducer_labels, mean_scores)):\n",
    "    plt.bar(bar_offsets + i, reducer_scores, label=label, color=COLORS[i])\n",
    "\n",
    "plt.title(\"Comparing feature reduction techniques\")\n",
    "plt.xlabel('Reduced number of features')\n",
    "plt.xticks(bar_offsets + len(reducer_labels) / 2, N_FEATURES_OPTIONS)\n",
    "plt.ylabel('Digit classification accuracy')\n",
    "plt.ylim((0, 1))\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
